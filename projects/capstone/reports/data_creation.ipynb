{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Import packages and create global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import textract\n",
    "from textblob import TextBlob, Word\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/'\n",
    "epub_path = \"/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/_epub_working/\"\n",
    "txt_path = \"/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/_txt/\"\n",
    "test_path = '/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/test_hold_out/'\n",
    "folders = ['sci-fi_top','sci-fi_flop','romance_top','romance_flop']\n",
    "folders2 = ['romance_flop']\n",
    "check_words = ['acknowledgements','table of contents','about the author', 'appendix', \n",
    "               'copyright','isbn','by this author', 'chapter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load profanity file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curses = pd.read_csv(path + 'other/profanity.csv')\n",
    "curses.drop('Unnamed: 1', inplace=True, axis=1)\n",
    "bad_words = curses.word.T.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract text from epub files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text file creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop through files in directory, convert file, save file in new folder\n",
    "def create_text_files(epub_path,txt_path):\n",
    "    for epub in os.listdir(epub_path):\n",
    "        try:\n",
    "            convert_epub_to_text(epub_path, epub, txt_path)\n",
    "        except:\n",
    "            print epub, \"failed\"\n",
    "            \n",
    "# function to extract text from epub\n",
    "def convert_epub_to_text(epub_path, epub_file, txt_path):\n",
    "    clean_text = ''\n",
    "    text_name = epub_file.replace(' ','_')[:-4]+'txt' #clean up filename and change file extention\n",
    "    \n",
    "    text = textract.process(epub_path+epub_file,encoding='utf_8') #extract text from epub\n",
    "    clean_text = text.decode('ascii', 'ignore').replace('\\n',' ') #trip out the unicode and return characters\n",
    "\n",
    "    text_file = open(txt_path+text_name, 'w') #save as text file\n",
    "    text_file.write(clean_text)\n",
    "    text_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_text_files(epub_path,txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the dataframes for the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# master function that calls functions below\n",
    "def create_data(path,folders,df):\n",
    "    df_name = df\n",
    "    df = create_df_from_files(path, folders) # create df and initial binary indicators\n",
    "    create_metrics(df)                       # create metric columns (this runs forever)\n",
    "    df.to_csv(path + df_name + '.csv')       # saves df as csv so we don't have to do the above again\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training data  - note: this takes many moons to run\n",
    "df = create_data(path,folders,'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create testing data\n",
    "df_test = create_data(test_path,folders,'df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check for front and back matter\n",
    "validate_content(df,check_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions that perform the above magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load txt files into dataframe, \n",
    "# give each entry a best_selling 1/0 entry and a sci_fi 1/0 (0=romance) indicator\n",
    "def create_df_from_files(path, folders):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for folder in folders:\n",
    "        if folder[-3:]=='top':\n",
    "            bs = 1\n",
    "        else:\n",
    "            bs = 0\n",
    "        if folder[:3]=='sci':\n",
    "            sf = 1\n",
    "        else:\n",
    "            sf = 0\n",
    "\n",
    "        for text_file in os.listdir(path+folder+'/'):\n",
    "            full_path = path + folder + '/' + text_file\n",
    "            if text_file.endswith((\".txt\")):\n",
    "                text  = open(full_path, 'r').read()\n",
    "                temp = pd.DataFrame({\n",
    "                        'best_seller': bs,\n",
    "                        'sci_fi': sf,\n",
    "                        'title': text_file[:-4].replace('_',' ').replace('-',' - '),\n",
    "                        'body': text.decode('ascii', 'ignore').replace('\\n',' ').replace('\\r','')}, \n",
    "                                    index=[0])\n",
    "                df = pd.concat([df, temp])\n",
    "\n",
    "    df = df.reset_index() # because index=[0]\n",
    "    del df['index']\n",
    "    return df\n",
    "\n",
    "# check for front and back matter in body\n",
    "# remaining issues are intentional usage in the body\n",
    "def validate_content(df, check_words):\n",
    "    for i in range(0,len(df)):\n",
    "        for word in check_words:\n",
    "            if word in df.iloc[i,1].lower():\n",
    "                print df.ix[i,3], ' : ', word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function bank for creating metrics\n",
    "\n",
    "def avg_sentence_len(text):\n",
    "    word_counts = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    sent_detect = PunktSentenceTokenizer()\n",
    "    sentences = sent_detect.sentences_from_text(text)\n",
    "    for sentence in sentences:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        word_counts.append(len(words))\n",
    "    avg_word_count = sum(word_counts)/len(word_counts)  \n",
    "    return avg_word_count\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "def get_token_words(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    return words\n",
    "\n",
    "def word_count(text):\n",
    "    words = get_token_words(text)\n",
    "    return len(words)\n",
    "\n",
    "def avg_word_len(text):\n",
    "    letter_counts = []\n",
    "    words = get_token_words(text)\n",
    "    for word in words:\n",
    "        letter_counts.append(len(word))\n",
    "    avg_word_len = sum(letter_counts)/len(letter_counts)\n",
    "    return avg_word_len\n",
    "\n",
    "def profanity_counter(text):\n",
    "    i=0\n",
    "    words = get_token_words(text)\n",
    "    for word in words:\n",
    "        if word in bad_words:\n",
    "            i+=1       \n",
    "    return i\n",
    "\n",
    "def lex_div(text):\n",
    "    words = get_token_words(text)\n",
    "    lexical_diversity = 1.0 * len(set(words)) / len(words)\n",
    "    return lexical_diversity\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "def to_blob(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob\n",
    "\n",
    "def assign_polarity(text):\n",
    "    blob = to_blob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def assign_subjectivity(text):\n",
    "    blob = to_blob(text)\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "def parse_pos(df,field):\n",
    "    for i in range(0,len(df)):\n",
    "        blob = TextBlob(df.ix[i,field])\n",
    "        tags = blob.tags\n",
    "        df_tags = pd.DataFrame(tags)\n",
    "        df_tags = df_tags.groupby([1]).count().reset_index()\n",
    "        for x in range(0,len(df_tags)):\n",
    "                df.ix[i, df_tags.ix[x,1] ] = df_tags.ix[x,0]\n",
    "        df.fillna(0,inplace=True)\n",
    "        \n",
    "def normalize_pos(df):\n",
    "    for row in range(0,len(df)):\n",
    "        for col in range(11,len(df.columns)):\n",
    "            df.iloc[row, col] = df.iloc[row,col]/df.ix[row,'word_count']\n",
    "            \n",
    "#-----------------------------------\n",
    "\n",
    "def clean_more(text):\n",
    "    return text.replace('.','. ').replace('`',' ').replace('*','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new columns of metrics and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_metrics(df):\n",
    "    df['body'] = df['body'].map(clean_more)\n",
    "    df['avg_sent_len'] = df['body'].map(avg_sentence_len)\n",
    "    df['word_count'] = df['body'].map(word_count)\n",
    "    df['avg_word_len'] = df['body'].map(avg_word_len)\n",
    "    df['lex_diversity'] = df['body'].map(lex_div)\n",
    "    df['polarity'] = df['body'].map(assign_polarity)\n",
    "    df['subjectivity'] = df['body'].map(assign_subjectivity)\n",
    "    df['profanity'] = df['body'].map(profanity_counter)\n",
    "    df['profane'] = 1. * df['profanity']/df['word_count']\n",
    "    parse_pos(df,'body')\n",
    "    normalize_pos(df)\n",
    "    \n",
    "    df.rename(columns={'CC':'conj_coord', 'CD':'number', 'DT':'determiner', 'EX':'exist_there',\n",
    "                  'FW':'foreign_word','IN':'conj_sub_prep','JJ':'adj','JJR':'adj_compare',\n",
    "                 'JJS':'adj_sup','MD':'verb_aux',  'NN':'noun','NNP':'noun_prop',\n",
    "                'NNPS':'noun_prop_pural',  'NNS':'noun_plural', 'PDT':'predeterm','PRP':'pronoun_pers',\n",
    "                'PRP$':'pronoun_poss',  'RB':'adv','RBR':'adv_compare','RBS':'adv_sup',\n",
    "                  'RP':'adv_part', 'TO':'inf_to',  'UH':'interject','VB':'verb_base',\n",
    "                 'VBD':'verb_past','VBG':'verb_ger','VBN':'verb_pp','VBP':'verb_sing_pres',\n",
    "                 'VBZ':'verb_3rd_sing_pres','WDT':'wh_determ','WP':'wh_pronoun','WP$':'wh_poss',\n",
    "                 'WRB':'wh_adv','POS':'poss_ending','SYM':'symbol','LS':'list_marker'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Double check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_pp</th>\n",
       "      <th>verb_sing_pres</th>\n",
       "      <th>verb_3rd_sing_pres</th>\n",
       "      <th>wh_determ</th>\n",
       "      <th>wh_pronoun</th>\n",
       "      <th>wh_poss</th>\n",
       "      <th>wh_adv</th>\n",
       "      <th>poss_ending</th>\n",
       "      <th>symbol</th>\n",
       "      <th>list_marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue  The sun is always just about to ris...</td>\n",
       "      <td>1</td>\n",
       "      <td>2312 - kim stanley robinson</td>\n",
       "      <td>14</td>\n",
       "      <td>166265</td>\n",
       "      <td>4</td>\n",
       "      <td>0.090717</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.465868</td>\n",
       "      <td>...</td>\n",
       "      <td>3916.0</td>\n",
       "      <td>3230.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            1   Prologue  The sun is always just about to ris...       1   \n",
       "\n",
       "                         title  avg_sent_len  word_count  avg_word_len  \\\n",
       "0  2312 - kim stanley robinson            14      166265             4   \n",
       "\n",
       "   lex_diversity  polarity  subjectivity     ...       verb_pp  \\\n",
       "0       0.090717     0.076      0.465868     ...        3916.0   \n",
       "\n",
       "   verb_sing_pres  verb_3rd_sing_pres  wh_determ  wh_pronoun  wh_poss  wh_adv  \\\n",
       "0          3230.0              1780.0      703.0       779.0      4.0   922.0   \n",
       "\n",
       "   poss_ending  symbol  list_marker  \n",
       "0          0.0     0.0          0.0  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_ger</th>\n",
       "      <th>verb_pp</th>\n",
       "      <th>verb_sing_pres</th>\n",
       "      <th>verb_3rd_sing_pres</th>\n",
       "      <th>wh_determ</th>\n",
       "      <th>wh_pronoun</th>\n",
       "      <th>wh_poss</th>\n",
       "      <th>wh_adv</th>\n",
       "      <th>symbol</th>\n",
       "      <th>list_marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue: Mei  Mei? Miss Carrie said. Please ...</td>\n",
       "      <td>1</td>\n",
       "      <td>caliban war - james corey</td>\n",
       "      <td>10</td>\n",
       "      <td>172918</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069813</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.453752</td>\n",
       "      <td>...</td>\n",
       "      <td>4970.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            1   Prologue: Mei  Mei? Miss Carrie said. Please ...       1   \n",
       "\n",
       "                       title  avg_sent_len  word_count  avg_word_len  \\\n",
       "0  caliban war - james corey            10      172918             4   \n",
       "\n",
       "   lex_diversity  polarity  subjectivity     ...       verb_ger  verb_pp  \\\n",
       "0       0.069813    0.0316      0.453752     ...         4970.0   3551.0   \n",
       "\n",
       "   verb_sing_pres  verb_3rd_sing_pres  wh_determ  wh_pronoun  wh_poss  wh_adv  \\\n",
       "0          3233.0              1737.0      576.0       781.0     16.0  1055.0   \n",
       "\n",
       "   symbol  list_marker  \n",
       "0     0.0          0.0  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
