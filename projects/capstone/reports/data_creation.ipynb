{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and create global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import textract\n",
    "from textblob import TextBlob, Word\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/'\n",
    "epub_path = \"/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/_epub_working/\"\n",
    "txt_path = \"/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/_txt/\"\n",
    "test_path = '/Users/katbishop/Desktop/DSI-SF2-bishopkd/projects/capstone/data/test_hold_out/'\n",
    "folders = ['sci-fi_top','sci-fi_flop','romance_top','romance_flop']\n",
    "folders2 = ['romance_flop']\n",
    "check_words = ['acknowledgements','table of contents','about the author', 'appendix', \n",
    "               'copyright','isbn','by this author', 'chapter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load profanity file\n",
    "curses = pd.read_csv(path + 'other/profanity.csv')\n",
    "curses.drop('Unnamed: 1', inplace=True, axis=1)\n",
    "bad_words = curses.word.T.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from epub files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_text_files(epub_path,txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Text file creation functions\n",
    "\n",
    "# loop through files in directory, convert file, save file in new folder\n",
    "def create_text_files(epub_path,txt_path):\n",
    "    for epub in os.listdir(epub_path):\n",
    "        try:\n",
    "            convert_epub_to_text(epub_path, epub, txt_path)\n",
    "        except:\n",
    "            print epub, \"failed\"\n",
    "            \n",
    "# function to extract text from epub\n",
    "def convert_epub_to_text(epub_path, epub_file, txt_path):\n",
    "    clean_text = ''\n",
    "    text_name = epub_file.replace(' ','_')[:-4]+'txt' #clean up filename and change file extention\n",
    "    \n",
    "    text = textract.process(epub_path+epub_file,encoding='utf_8') #extract text from epub\n",
    "    clean_text = text.decode('ascii', 'ignore').replace('\\n',' ') #trip out the unicode and return characters\n",
    "\n",
    "    text_file = open(txt_path+text_name, 'w') #save as text file\n",
    "    text_file.write(clean_text)\n",
    "    text_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataframes for the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(path,folders,df):\n",
    "    df_name = df\n",
    "    df = create_df_from_files(path, folders) # create df and initial binary indicators\n",
    "    create_metrics(df)                       # create metric columns (this runs forever)\n",
    "    df.to_csv(path + df_name + '.csv')       # saves df as csv so we don't have to do the above again\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training data\n",
    "create_data(path,folders,'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create testing data\n",
    "df_test = create_data(test_path,folders,'df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check for front and back matter\n",
    "validate_content(df,check_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The functions that perform the above magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load txt files into dataframe, \n",
    "# give each entry a best_selling 1/0 entry and a sci_fi 1/0 (0=romance) indicator\n",
    "def create_df_from_files(path, folders):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for folder in folders:\n",
    "        if folder[-3:]=='top':\n",
    "            bs = 1\n",
    "        else:\n",
    "            bs = 0\n",
    "        if folder[:3]=='sci':\n",
    "            sf = 1\n",
    "        else:\n",
    "            sf = 0\n",
    "\n",
    "        for text_file in os.listdir(path+folder+'/'):\n",
    "            full_path = path + folder + '/' + text_file\n",
    "            if text_file.endswith((\".txt\")):\n",
    "                text  = open(full_path, 'r').read()\n",
    "                temp = pd.DataFrame({\n",
    "                        'best_seller': bs,\n",
    "                        'sci_fi': sf,\n",
    "                        'title': text_file[:-4].replace('_',' ').replace('-',' - '),\n",
    "                        'body': text.decode('ascii', 'ignore').replace('\\n',' ').replace('\\r','')}, \n",
    "                                    index=[0])\n",
    "                df = pd.concat([df, temp])\n",
    "\n",
    "    df = df.reset_index() # because index=[0]\n",
    "    del df['index']\n",
    "    return df\n",
    "\n",
    "# check for front and back matter in body\n",
    "# remaining issues are intentional usage in the body\n",
    "def validate_content(df, check_words):\n",
    "    for i in range(0,len(df)):\n",
    "        for word in check_words:\n",
    "            if word in df.iloc[i,1].lower():\n",
    "                print df.ix[i,3], ' : ', word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function bank for creating metrics\n",
    "\n",
    "def avg_sentence_len(text):\n",
    "    word_counts = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    sent_detect = PunktSentenceTokenizer()\n",
    "    sentences = sent_detect.sentences_from_text(text)\n",
    "    for sentence in sentences:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        word_counts.append(len(words))\n",
    "    avg_word_count = sum(word_counts)/len(word_counts)  \n",
    "    return avg_word_count\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "def get_token_words(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(text)\n",
    "    return words\n",
    "\n",
    "def word_count(text):\n",
    "    words = get_token_words(text)\n",
    "    return len(words)\n",
    "\n",
    "def avg_word_len(text):\n",
    "    letter_counts = []\n",
    "    words = get_token_words(text)\n",
    "    for word in words:\n",
    "        letter_counts.append(len(word))\n",
    "    avg_word_len = sum(letter_counts)/len(letter_counts)\n",
    "    return avg_word_len\n",
    "\n",
    "def profanity_counter(text):\n",
    "    i=0\n",
    "    words = get_token_words(text)\n",
    "    for word in words:\n",
    "        if word in bad_words:\n",
    "            i+=1       \n",
    "    return i\n",
    "\n",
    "def lex_div(text):\n",
    "    words = get_token_words(text)\n",
    "    lexical_diversity = 1.0 * len(set(words)) / len(words)\n",
    "    return lexical_diversity\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "def to_blob(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob\n",
    "\n",
    "def assign_polarity(text):\n",
    "    blob = to_blob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def assign_subjectivity(text):\n",
    "    blob = to_blob(text)\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "def parse_pos(df,field):\n",
    "    for i in range(0,len(df)):\n",
    "        blob = TextBlob(df.ix[i,field])\n",
    "        tags = blob.tags\n",
    "        df_tags = pd.DataFrame(tags)\n",
    "        df_tags = df_tags.groupby([1]).count().reset_index()\n",
    "        for x in range(0,len(df_tags)):\n",
    "                df.ix[i, df_tags.ix[x,1] ] = df_tags.ix[x,0]\n",
    "        df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new columns of metrics\n",
    "# note: this is take a very long time to run\n",
    "def create_metrics(df):\n",
    "    df['avg_sent_len'] = df['body'].map(avg_sentence_len)\n",
    "    df['word_count'] = df['body'].map(word_count)\n",
    "    df['avg_word_len'] = df['body'].map(avg_word_len)\n",
    "    df['lex_diversity'] = df['body'].map(lex_div)\n",
    "    df['polarity'] = df['body'].map(assign_polarity)\n",
    "    df['subjectivity'] = df['body'].map(assign_subjectivity)\n",
    "    df['profanity'] = df['body'].map(profanity_counter)\n",
    "    df['profane'] = 1. * df['profanity']/df['word_count']\n",
    "    parse_pos(df,'body')\n",
    "    \n",
    "    df.rename(columns={'CC':'conj_coord', 'CD':'number', 'DT':'determiner', 'EX':'exist_there',\n",
    "                  'FW':'foreign_word','IN':'conj_sub_prep','JJ':'adj','JJR':'adj_compare',\n",
    "                 'JJS':'adj_sup','MD':'verb_aux',  'NN':'noun','NNP':'noun_prop',\n",
    "                'NNPS':'noun_prop_pural',  'NNS':'noun_plural', 'PDT':'predeterm','PRP':'pronoun_pers',\n",
    "                'PRP$':'pronoun_poss',  'RB':'adv','RBR':'adv_compare','RBS':'adv_sup',\n",
    "                  'RP':'adv_part', 'TO':'inf_to',  'UH':'interject','VB':'verb_base',\n",
    "                 'VBD':'verb_past','VBG':'verb_ger','VBN':'verb_pp','VBP':'verb_sing_pres',\n",
    "                 'VBZ':'verb_3rd_sing_pres','WDT':'wh_determ','WP':'wh_pronoun','WP$':'wh_poss',\n",
    "                 'WRB':'wh_adv','POS':'poss_ending','SYM':'symbol','LS':'list_marker'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_pp</th>\n",
       "      <th>verb_sing_pres</th>\n",
       "      <th>verb_3rd_sing_pres</th>\n",
       "      <th>wh_determ</th>\n",
       "      <th>wh_pronoun</th>\n",
       "      <th>wh_poss</th>\n",
       "      <th>wh_adv</th>\n",
       "      <th>poss_ending</th>\n",
       "      <th>symbol</th>\n",
       "      <th>list_marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Prologue  The sun is always just about to ris...</td>\n",
       "      <td>1</td>\n",
       "      <td>2312 - kim stanley robinson</td>\n",
       "      <td>14</td>\n",
       "      <td>166265</td>\n",
       "      <td>4</td>\n",
       "      <td>0.090717</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.465868</td>\n",
       "      <td>...</td>\n",
       "      <td>3916.0</td>\n",
       "      <td>3230.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            1   Prologue  The sun is always just about to ris...       1   \n",
       "\n",
       "                         title  avg_sent_len  word_count  avg_word_len  \\\n",
       "0  2312 - kim stanley robinson            14      166265             4   \n",
       "\n",
       "   lex_diversity  polarity  subjectivity     ...       verb_pp  \\\n",
       "0       0.090717     0.076      0.465868     ...        3916.0   \n",
       "\n",
       "   verb_sing_pres  verb_3rd_sing_pres  wh_determ  wh_pronoun  wh_poss  wh_adv  \\\n",
       "0          3230.0              1780.0      703.0       779.0      4.0   922.0   \n",
       "\n",
       "   poss_ending  symbol  list_marker  \n",
       "0          0.0     0.0          0.0  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_seller</th>\n",
       "      <th>body</th>\n",
       "      <th>sci_fi</th>\n",
       "      <th>title</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>lex_diversity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>verb_past</th>\n",
       "      <th>verb_ger</th>\n",
       "      <th>verb_pp</th>\n",
       "      <th>verb_sing_pres</th>\n",
       "      <th>verb_3rd_sing_pres</th>\n",
       "      <th>wh_determ</th>\n",
       "      <th>wh_pronoun</th>\n",
       "      <th>wh_poss</th>\n",
       "      <th>wh_adv</th>\n",
       "      <th>poss_ending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Manolo, Jess called out, dont worry about the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>jess and the love test - chastity foelds</td>\n",
       "      <td>9</td>\n",
       "      <td>7318</td>\n",
       "      <td>4</td>\n",
       "      <td>0.265236</td>\n",
       "      <td>0.097742</td>\n",
       "      <td>0.490602</td>\n",
       "      <td>...</td>\n",
       "      <td>727.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Judd looked in the car and watched Lisa rif...</td>\n",
       "      <td>0</td>\n",
       "      <td>lisa and her beaver - geoff lynch</td>\n",
       "      <td>10</td>\n",
       "      <td>80356</td>\n",
       "      <td>3</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>0.465601</td>\n",
       "      <td>...</td>\n",
       "      <td>7437.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_seller                                               body  sci_fi  \\\n",
       "0            0  Manolo, Jess called out, dont worry about the ...       0   \n",
       "1            0     Judd looked in the car and watched Lisa rif...       0   \n",
       "\n",
       "                                      title  avg_sent_len  word_count  \\\n",
       "0  jess and the love test - chastity foelds             9        7318   \n",
       "1         lisa and her beaver - geoff lynch            10       80356   \n",
       "\n",
       "   avg_word_len  lex_diversity  polarity  subjectivity     ...       \\\n",
       "0             4       0.265236  0.097742      0.490602     ...        \n",
       "1             3       0.068470 -0.001299      0.465601     ...        \n",
       "\n",
       "   verb_past  verb_ger  verb_pp  verb_sing_pres  verb_3rd_sing_pres  \\\n",
       "0      727.0     146.0     98.0           108.0               115.0   \n",
       "1     7437.0    1960.0    964.0          3130.0              1180.0   \n",
       "\n",
       "   wh_determ  wh_pronoun  wh_poss  wh_adv  poss_ending  \n",
       "0       20.0        31.0      1.0    51.0          0.0  \n",
       "1      167.0       729.0      0.0   627.0         12.0  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
